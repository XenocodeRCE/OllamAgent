# OllamAgent
Ollama agent solution

# TODO
- [ ] use llama3.1 128k context as RAG (check token cap, `nltk.word_tokenize(text)`
- [ ] make queue and execution order
- [ ] from this, make mission (= collection of tasks)
- [ ] llama3.1 instruct parser : if LLM sends back instructions
