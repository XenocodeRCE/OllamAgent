<p align="center">
  <img src="https://raw.githubusercontent.com/XenocodeRCE/OllamAgent/main/logo.svg" alt="Logo" style="width:500px;">
</p>

# OllamAgent ü¶ô
Ollama agent solution


## Agents

```
{
  "type": "WORKER",
  "nom": "001",
  "t√¢che": "Analyse des donn√©es",
  "contexte": {
    "mod√®les": [
      "Mod√®le A",
      "Mod√®le B"
    ],
    "besoins": [
      {
        "nom": "Besoin1",
        "contenu": ""
      },
      {
        "nom": "Besoin2",
        "contenu": "Instructions sp√©cifiques"
      }
    ]
  }
}
```
**Explications : **

- type : WORKER (agent) / SUPERVISOR (√©valuateur)
- nom : _
- t√¢che : ce que l'agent doit faire, ce pour quoi il est fait
- contexte :
  - mod√®les : utilis√©s comme "bons" mod√®les pour l'agent
  - besoins : ce dont l'agent a besoin pour faire sa t√¢che

  
**√Ä placer dans le dossier** `bin/Agents/`.

## USAGE

```csharp
var d = new Discussion("R√©diger une dissertation de philosophie.");
// r√©cup√®re les agents dans le dossier /Agents automatiquement
var rep = await d.GetAgent("001").ExecuteTask();
// r√©cup√®re les 'besoins' chez les autres agents, s'il n'y a pas : demande √† l'utilisateur
```

# TODO
- [ ] llama3.1 instruct parser : if LLM sends back instructions
